{"type": "text", "bbox": [48, 367, 287, 556], "res": [{"text": "As shown in Fig. 4, rectangular initial proposals in 2D", "confidence": 0.9857132434844971, "text_region": [[48.0, 366.0], [289.0, 366.0], [289.0, 380.0], [48.0, 380.0]]}, {"text": "screen space will be distorted when projected into 3D", "confidence": 0.9950751066207886, "text_region": [[48.0, 378.0], [289.0, 378.0], [289.0, 392.0], [48.0, 392.0]]}, {"text": "world. Thus, we need to first rectify the proposals in 3D", "confidence": 0.9921708106994629, "text_region": [[48.0, 390.0], [289.0, 390.0], [289.0, 404.0], [48.0, 404.0]]}, {"text": "world. We project the center point of the initial proposals", "confidence": 0.9815002083778381, "text_region": [[49.0, 402.0], [289.0, 402.0], [289.0, 416.0], [49.0, 416.0]]}, {"text": "into 3D space, and re-initialize orthogonal squares on the", "confidence": 0.9789265394210815, "text_region": [[48.0, 414.0], [289.0, 414.0], [289.0, 428.0], [48.0, 428.0]]}, {"text": "corresponding mesh surfaces around the center points: the", "confidence": 0.992233157157898, "text_region": [[48.0, 427.0], [289.0, 427.0], [289.0, 440.0], [48.0, 440.0]]}, {"text": "horizontal sides are orrhogonal to the gravity direction. The", "confidence": 0.9866449236869812, "text_region": [[48.0, 439.0], [288.0, 439.0], [288.0, 451.0], [48.0, 451.0]]}, {"text": "side lengths are set to the shortest sides of the quadrilaterals", "confidence": 0.9906317591667175, "text_region": [[48.0, 449.0], [287.0, 449.0], [287.0, 462.0], [48.0, 462.0]]}, {"text": "created by projecting the four corners of initial proposals", "confidence": 0.9855031967163086, "text_region": [[48.0, 461.0], [288.0, 461.0], [288.0, 475.0], [48.0, 475.0]]}, {"text": "into the 3D space. Then we enlarge the widths and heights", "confidence": 0.9950569272041321, "text_region": [[48.0, 473.0], [289.0, 473.0], [289.0, 487.0], [48.0, 487.0]]}, {"text": "along the horizontal and vertical sides alternatively.", "confidence": 0.9920628666877747, "text_region": [[48.0, 485.0], [268.0, 485.0], [268.0, 499.0], [48.0, 499.0]]}, {"text": "The", "confidence": 0.9995322823524475, "text_region": [[263.0, 486.0], [288.0, 486.0], [288.0, 497.0], [263.0, 497.0]]}, {"text": "expansion of one direction stops when the sides of that di-", "confidence": 0.9940833449363708, "text_region": [[48.0, 497.0], [288.0, 497.0], [288.0, 511.0], [48.0, 511.0]]}, {"text": "rection get off the surface, hit other meshes, or reach the", "confidence": 0.9794268608093262, "text_region": [[48.0, 509.0], [289.0, 509.0], [289.0, 523.0], [48.0, 523.0]]}, {"text": "preset maximum expansion ratio. The proposed refining al-", "confidence": 0.9836646914482117, "text_region": [[47.0, 522.0], [288.0, 521.0], [288.0, 535.0], [47.0, 536.0]]}, {"text": "gorithm works in 3D world space, and is able to produce", "confidence": 0.9919589161872864, "text_region": [[48.0, 534.0], [289.0, 534.0], [289.0, 547.0], [48.0, 547.0]]}, {"text": "natural homography transformation in 2D screen space.", "confidence": 0.9925516247749329, "text_region": [[48.0, 545.0], [273.0, 545.0], [273.0, 559.0], [48.0, 559.0]]}], "img_idx": 0, "score": 0.9921825528144836}
{"type": "text", "bbox": [307, 200, 545, 340], "res": [{"text": "Figure 4: Ilustration of the refinement of initial proposals.", "confidence": 0.9792287349700928, "text_region": [[307.0, 198.0], [546.0, 198.0], [546.0, 212.0], [307.0, 212.0]]}, {"text": "We draw green bounding boxes to represent proposals in 2D", "confidence": 0.9749337434768677, "text_region": [[306.0, 209.0], [548.0, 209.0], [548.0, 226.0], [306.0, 226.0]]}, {"text": "screen space, and use planar meshes to represent proposals", "confidence": 0.9829503893852234, "text_region": [[307.0, 223.0], [547.0, 223.0], [547.0, 237.0], [307.0, 237.0]]}, {"text": "in 3D space. (1) Initial proposals are made in 2D space.", "confidence": 0.9842795133590698, "text_region": [[305.0, 235.0], [546.0, 235.0], [546.0, 248.0], [305.0, 248.0]]}, {"text": "(2) When we project them into 3D world and inspect them", "confidence": 0.9790446758270264, "text_region": [[307.0, 247.0], [547.0, 247.0], [547.0, 260.0], [307.0, 260.0]]}, {"text": "from the front view, they are in distorted forms. (3) Based", "confidence": 0.9827826619148254, "text_region": [[306.0, 257.0], [547.0, 257.0], [547.0, 270.0], [306.0, 270.0]]}, {"text": "on the sizes of the distorted proposals and the positions of", "confidence": 0.9826139807701111, "text_region": [[306.0, 269.0], [547.0, 269.0], [547.0, 283.0], [306.0, 283.0]]}, {"text": "the center points, we re-initialize orthogonal squares on the", "confidence": 0.9953061938285828, "text_region": [[306.0, 282.0], [547.0, 282.0], [547.0, 296.0], [306.0, 296.0]]}, {"text": "same surfaces with horizontal sides orthogonal to the grav-", "confidence": 0.9978339672088623, "text_region": [[306.0, 294.0], [547.0, 294.0], [547.0, 308.0], [306.0, 308.0]]}, {"text": "ity direction. (5) Then we expand the squares. (6) Finally,", "confidence": 0.971230149269104, "text_region": [[306.0, 305.0], [546.0, 305.0], [546.0, 319.0], [306.0, 319.0]]}, {"text": "we obtain text regions in 2D screen space with natural per-", "confidence": 0.9760704040527344, "text_region": [[305.0, 316.0], [548.0, 317.0], [548.0, 334.0], [305.0, 333.0]]}, {"text": "spective distortion.", "confidence": 0.9952915906906128, "text_region": [[306.0, 331.0], [385.0, 330.0], [386.0, 343.0], [306.0, 345.0]]}], "img_idx": 0, "score": 0.9917685985565186}
{"type": "text", "bbox": [49, 179, 286, 332], "res": [{"text": "In computer graphics, normal values are unit vectors that", "confidence": 0.9862339496612549, "text_region": [[47.0, 178.0], [288.0, 178.0], [288.0, 192.0], [47.0, 192.0]]}, {"text": "are perpendicular to a surface. Therefore, when projected", "confidence": 0.9927435517311096, "text_region": [[48.0, 190.0], [288.0, 190.0], [288.0, 203.0], [48.0, 203.0]]}, {"text": "to 2D screen space, a region with similar normal values", "confidence": 0.9881617426872253, "text_region": [[47.0, 201.0], [289.0, 201.0], [289.0, 215.0], [47.0, 215.0]]}, {"text": "tends to be a well-defined region to embed text on. We find", "confidence": 0.9904940128326416, "text_region": [[48.0, 213.0], [289.0, 213.0], [289.0, 227.0], [48.0, 227.0]]}, {"text": "valid image regions by applying sliding windows of 64 \u00d7 64", "confidence": 0.9858191013336182, "text_region": [[49.0, 226.0], [289.0, 226.0], [289.0, 240.0], [49.0, 240.0]]}, {"text": "pixels across the surface normal map, and retrieve those", "confidence": 0.9911989569664001, "text_region": [[48.0, 238.0], [289.0, 238.0], [289.0, 251.0], [48.0, 251.0]]}, {"text": "with smoorh surface normal: the minimum cosine similar-", "confidence": 0.9922375679016113, "text_region": [[48.0, 249.0], [288.0, 249.0], [288.0, 262.0], [48.0, 262.0]]}, {"text": "ity value between any two pixels is larger than a threshold", "confidence": 0.9913721680641174, "text_region": [[47.0, 260.0], [288.0, 260.0], [288.0, 273.0], [47.0, 273.0]]}, {"text": ". We set I to 0.95, which proves to produce reasonable", "confidence": 0.966877818107605, "text_region": [[47.0, 273.0], [289.0, 273.0], [289.0, 286.0], [47.0, 286.0]]}, {"text": "results. We randomly sample at most 10 non-overlapping", "confidence": 0.9881572127342224, "text_region": [[46.0, 282.0], [290.0, 284.0], [290.0, 301.0], [46.0, 299.0]]}, {"text": "valid image regions to make the initial proposals. Making", "confidence": 0.9929448962211609, "text_region": [[47.0, 294.0], [290.0, 296.0], [290.0, 313.0], [47.0, 311.0]]}, {"text": "proposals from normal maps is an efficient way to find po-", "confidence": 0.9909241199493408, "text_region": [[47.0, 310.0], [288.0, 309.0], [288.0, 323.0], [47.0, 324.0]]}, {"text": "tential and visible regions.", "confidence": 0.9877416491508484, "text_region": [[48.0, 322.0], [157.0, 322.0], [157.0, 335.0], [48.0, 335.0]]}], "img_idx": 0, "score": 0.9904428124427795}
{"type": "text", "bbox": [49, 74, 287, 142], "res": [{"text": "als; (2) Initial proposals are then projected to and refined", "confidence": 0.9938428401947021, "text_region": [[48.0, 73.0], [289.0, 73.0], [289.0, 86.0], [48.0, 86.0]]}, {"text": "in the 3D world using object meshes. Finally, we sample", "confidence": 0.9738758206367493, "text_region": [[48.0, 85.0], [289.0, 85.0], [289.0, 99.0], [48.0, 99.0]]}, {"text": "a subset from the refined proposals to render. To avoid oc-", "confidence": 0.9918691515922546, "text_region": [[48.0, 97.0], [287.0, 97.0], [287.0, 111.0], [48.0, 111.0]]}, {"text": "clusion among proposals, we projeet them back to screen ", "confidence": 0.967591404914856, "text_region": [[47.0, 108.0], [290.0, 108.0], [290.0, 125.0], [47.0, 125.0]]}, {"text": "space, and discard regions that overlap with each other one", "confidence": 0.9702562093734741, "text_region": [[47.0, 122.0], [289.0, 121.0], [289.0, 135.0], [47.0, 136.0]]}, {"text": "by one in a shuffled order until occlusion is eliminated.", "confidence": 0.9959608316421509, "text_region": [[48.0, 134.0], [270.0, 134.0], [270.0, 147.0], [48.0, 147.0]]}], "img_idx": 0, "score": 0.990275502204895}
{"type": "text", "bbox": [49, 583, 287, 712], "res": [{"text": "Generating Text Images: Given text regions as proposed", "confidence": 0.997970461845398, "text_region": [[47.0, 581.0], [289.0, 582.0], [289.0, 596.0], [47.0, 595.0]]}, {"text": "and refined in section 3.4, the text generation module sam-", "confidence": 0.992315948009491, "text_region": [[47.0, 593.0], [288.0, 595.0], [288.0, 608.0], [47.0, 606.0]]}, {"text": "ples text content and renders text images with certain fonts", "confidence": 0.9916216731071472, "text_region": [[48.0, 607.0], [288.0, 607.0], [288.0, 621.0], [48.0, 621.0]]}, {"text": "and text colors. The numbers of lines and characters per", "confidence": 0.9830668568611145, "text_region": [[47.0, 618.0], [288.0, 619.0], [288.0, 633.0], [47.0, 632.0]]}, {"text": "line are determined by the font size and the size of refined", "confidence": 0.9843721389770508, "text_region": [[48.0, 630.0], [288.0, 630.0], [288.0, 643.0], [48.0, 643.0]]}, {"text": "proposals in 2D space to make sure the characters are not", "confidence": 0.9834736585617065, "text_region": [[48.0, 643.0], [289.0, 643.0], [289.0, 656.0], [48.0, 656.0]]}, {"text": "too small and ensure legibility. For a fairer comparison, we", "confidence": 0.9904711842536926, "text_region": [[47.0, 653.0], [289.0, 654.0], [289.0, 668.0], [47.0, 667.0]]}, {"text": "also use the same font set from Google Fonts ~ as SynthText", "confidence": 0.9864382743835449, "text_region": [[48.0, 666.0], [289.0, 666.0], [289.0, 679.0], [48.0, 679.0]]}, {"text": "when the distances from the rectangular proposals\u2019 corners to the near-", "confidence": 0.9531213641166687, "text_region": [[59.0, 684.0], [288.0, 684.0], [288.0, 697.0], [59.0, 697.0]]}, {"text": "est point on the underlying surface mesh exceed certain threshold", "confidence": 0.9895317554473877, "text_region": [[47.0, 695.0], [261.0, 694.0], [261.0, 705.0], [47.0, 706.0]]}, {"text": "httpa://fonta.goagle,con/", "confidence": 0.8442527055740356, "text_region": [[59.0, 702.0], [183.0, 703.0], [183.0, 717.0], [59.0, 716.0]]}], "img_idx": 0, "score": 0.9892895817756653}
{"type": "text", "bbox": [307, 487, 545, 616], "res": [{"text": "The proposed synthesis engine is implemented based on", "confidence": 0.9875515103340149, "text_region": [[318.0, 486.0], [547.0, 486.0], [547.0, 500.0], [318.0, 500.0]]}, {"text": "UE4.22 and the UnrealCV plugin. On an ubuntu worksta-", "confidence": 0.9962029457092285, "text_region": [[307.0, 498.0], [546.0, 498.0], [546.0, 512.0], [307.0, 512.0]]}, {"text": "tion with an 8-core Intel CPU, an NVIDIA GeForce RTX", "confidence": 0.993915319442749, "text_region": [[307.0, 510.0], [547.0, 510.0], [547.0, 523.0], [307.0, 523.0]]}, {"text": "2070 GPU, and 16G RAM, the synthesis speed is 0.7-1.5", "confidence": 0.9850976467132568, "text_region": [[306.0, 521.0], [548.0, 522.0], [548.0, 536.0], [306.0, 535.0]]}, {"text": "seconds per image with a resolution of 1080 \u00d7 720, depend-", "confidence": 0.9786992073059082, "text_region": [[308.0, 535.0], [546.0, 535.0], [546.0, 547.0], [308.0, 547.0]]}, {"text": "ing on the complexity of the scene model.", "confidence": 0.9950839877128601, "text_region": [[307.0, 546.0], [477.0, 546.0], [477.0, 559.0], [307.0, 559.0]]}, {"text": "We collect 30 scene models from the official UE4 mar-", "confidence": 0.9827533960342407, "text_region": [[318.0, 558.0], [547.0, 558.0], [547.0, 571.0], [318.0, 571.0]]}, {"text": "ketplace. The engine is used to generate 600K\u2019 scene text", "confidence": 0.9751784801483154, "text_region": [[307.0, 570.0], [547.0, 570.0], [547.0, 584.0], [307.0, 584.0]]}, {"text": "images with English words.With the same configura-", "confidence": 0.990692675113678, "text_region": [[306.0, 582.0], [547.0, 582.0], [547.0, 596.0], [306.0, 596.0]]}, {"text": "tion, we also generate a multilingual version, making it the", "confidence": 0.9759856462478638, "text_region": [[306.0, 594.0], [548.0, 594.0], [548.0, 608.0], [306.0, 608.0]]}, {"text": "largest multilingual scene text dataset.", "confidence": 0.993138313293457, "text_region": [[307.0, 607.0], [463.0, 607.0], [463.0, 620.0], [307.0, 620.0]]}], "img_idx": 0, "score": 0.9891139268875122}
{"type": "text", "bbox": [307, 667, 545, 712], "res": [{"text": "We first verify the effectiveness of the proposed engine", "confidence": 0.9655026793479919, "text_region": [[318.0, 663.0], [547.0, 664.0], [547.0, 681.0], [318.0, 680.0]]}, {"text": "by training detectors on the synthesized images and evaluat-", "confidence": 0.9940801858901978, "text_region": [[306.0, 678.0], [546.0, 678.0], [546.0, 692.0], [306.0, 692.0]]}, {"text": "ing them on real image datasets. We use a previous yet time-", "confidence": 0.9895780086517334, "text_region": [[307.0, 690.0], [546.0, 690.0], [546.0, 704.0], [307.0, 704.0]]}, {"text": "tested state-of-the-art model, EAST [53], which is fast and", "confidence": 0.9952322840690613, "text_region": [[307.0, 702.0], [548.0, 702.0], [548.0, 715.0], [307.0, 715.0]]}], "img_idx": 0, "score": 0.988129734992981}
{"type": "text", "bbox": [307, 353, 545, 460], "res": [{"text": "does. We also use the same text corpus, Newsgroup20. The", "confidence": 0.9877306818962097, "text_region": [[306.0, 352.0], [547.0, 353.0], [547.0, 367.0], [306.0, 366.0]]}, {"text": "generated text images have zero alpha values on non-stroke", "confidence": 0.9908490777015686, "text_region": [[307.0, 366.0], [548.0, 366.0], [548.0, 380.0], [307.0, 380.0]]}, {"text": "pixels, and non zero for others.", "confidence": 0.9871188402175903, "text_region": [[306.0, 377.0], [434.0, 376.0], [434.0, 390.0], [306.0, 391.0]]}, {"text": "Rendering Text in 3D World: We first perform triangula-", "confidence": 0.9962993264198303, "text_region": [[307.0, 389.0], [546.0, 389.0], [546.0, 403.0], [307.0, 403.0]]}, {"text": "tion for the refined proposals to generate planar triangular", "confidence": 0.9982703328132629, "text_region": [[307.0, 401.0], [547.0, 401.0], [547.0, 415.0], [307.0, 415.0]]}, {"text": "meshes that are closely attached to the underlying surface.", "confidence": 0.9895715117454529, "text_region": [[307.0, 413.0], [547.0, 413.0], [547.0, 427.0], [307.0, 427.0]]}, {"text": "Then we load the text images as texture onto the generated", "confidence": 0.9925652742385864, "text_region": [[306.0, 424.0], [548.0, 425.0], [548.0, 439.0], [306.0, 438.0]]}, {"text": "meshes. We also randomly sample the texture attributes,", "confidence": 0.9788508415222168, "text_region": [[307.0, 437.0], [547.0, 437.0], [547.0, 450.0], [307.0, 450.0]]}, {"text": "such as the ratio of diffuse and specular reflection.", "confidence": 0.9733484983444214, "text_region": [[307.0, 449.0], [510.0, 449.0], [510.0, 463.0], [307.0, 463.0]]}], "img_idx": 0, "score": 0.9557155966758728}
{"type": "title", "bbox": [308, 629, 510, 658], "res": [{"text": "4. Experiments on Scene Text Detection", "confidence": 0.9823815226554871, "text_region": [[307.0, 629.0], [512.0, 629.0], [512.0, 643.0], [307.0, 643.0]]}, {"text": "4.1. Settings", "confidence": 0.9629502892494202, "text_region": [[307.0, 645.0], [368.0, 649.0], [367.0, 663.0], [306.0, 659.0]]}], "img_idx": 0, "score": 0.9673237204551697}
{"type": "title", "bbox": [49, 348, 218, 357], "res": [{"text": "3.4.2 Refining Proposals in 3D Worlds", "confidence": 0.9865475296974182, "text_region": [[48.0, 346.0], [220.0, 346.0], [220.0, 360.0], [48.0, 360.0]]}], "img_idx": 0, "score": 0.9599995017051697}
{"type": "title", "bbox": [49, 160, 234, 170], "res": [{"text": "3.4.1 Initial Proposals from Normal Maps", "confidence": 0.9768438339233398, "text_region": [[47.0, 157.0], [237.0, 159.0], [236.0, 173.0], [47.0, 171.0]]}], "img_idx": 0, "score": 0.9370947480201721}
{"type": "title", "bbox": [49, 565, 142, 574], "res": [{"text": "3.5. Text Rendering", "confidence": 0.9611848592758179, "text_region": [[47.0, 562.0], [144.0, 563.0], [144.0, 577.0], [47.0, 576.0]]}], "img_idx": 0, "score": 0.9354118704795837}
{"type": "title", "bbox": [309, 469, 438, 478], "res": [{"text": "3.6. Implementation Details", "confidence": 0.9965628981590271, "text_region": [[307.0, 467.0], [440.0, 467.0], [440.0, 481.0], [307.0, 481.0]]}], "img_idx": 0, "score": 0.9311609268188477}
{"type": "figure", "bbox": [303, 67, 546, 192], "res": [{"text": "(4)Original View", "confidence": 0.9299747347831726, "text_region": [[318.0, 184.0], [367.0, 184.0], [367.0, 191.0], [318.0, 191.0]]}, {"text": "(5) Refined Proposal", "confidence": 0.9968282580375671, "text_region": [[393.0, 183.0], [453.0, 183.0], [453.0, 193.0], [393.0, 193.0]]}, {"text": "(6) Eml", "confidence": 0.8221644163131714, "text_region": [[475.0, 184.0], [496.0, 184.0], [496.0, 191.0], [475.0, 191.0]]}, {"text": "edded Tex", "confidence": 0.9245461225509644, "text_region": [[499.0, 184.0], [528.0, 184.0], [528.0, 191.0], [499.0, 191.0]]}], "img_idx": 0, "score": 0.9590279459953308}
